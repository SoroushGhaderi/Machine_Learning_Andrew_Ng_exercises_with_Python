{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise 4:  Neural Networks Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise, you will implement the backpropagation algorithm for neural networks and apply it to the task of hand-written digit recognition. Before starting on the programming exercise, we strongly recommend watching the video lectures and completing the review questions for the associated topics.\n",
    "\n",
    "\n",
    "All the information you need for solving this assignment is in this notebook, and all the code you will be implementing will take place within this notebook. The assignment can be promptly submitted to the coursera grader directly from this notebook (code and instructions are included below).\n",
    "\n",
    "Before we begin with the exercises, we need to import all libraries required for this programming exercise. Throughout the course, we will be using [`numpy`](http://www.numpy.org/) for all arrays and matrix operations, [`matplotlib`](https://matplotlib.org/) for plotting, and [`scipy`](https://docs.scipy.org/doc/scipy/reference/) for scientific and numerical computation functions and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "In the previous exercise, you implemented feedforward propagation for neural networks and used it to predict handwritten digits with the weights we provided. In this exercise, you will implement the backpropagation algorithm to learn the parameters for the neural network.\n",
    "\n",
    "We start the exercise by first loading the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and training data stored in arrays X, y\n",
    "data= loadmat(\"ex4data1.mat\")\n",
    "X= data[\"X\"]\n",
    "y= data[\"y\"]\n",
    "# # set the zero digit to 0, rather than its mapped 10 in this dataset\n",
    "# This is an artifact due to the fact that this dataset was used in \n",
    "# MATLAB where there is no index 0\n",
    "y[y == 10] = 0\n",
    "# size of training data\n",
    "m= y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Visualizing the data\n",
    "\n",
    "You will begin by visualizing a subset of the training set, using the function `display_data`, which is the function we provided below. The dataset is also the same one you used in the previous exercise.\n",
    "\n",
    "There are 5000 training examples in `ex4data1.mat`, where each training example is a 20 pixel by 20 pixel grayscale image of the digit. Each pixel is represented by a floating point number indicating the grayscale intensity at that location. The 20 by 20 grid of pixels is “unrolled” into a 400-dimensional vector. Each\n",
    "of these training examples becomes a single row in our data matrix $X$. This gives us a 5000 by 400 matrix $X$ where every row is a training example for a handwritten digit image.\n",
    "\n",
    "$$ X = \\begin{bmatrix} - \\left(x^{(1)} \\right)^T - \\\\\n",
    "- \\left(x^{(2)} \\right)^T - \\\\\n",
    "\\vdots \\\\\n",
    "- \\left(x^{(m)} \\right)^T - \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The second part of the training set is a 5000-dimensional vector `y` that contains labels for the training set. \n",
    "The following cell randomly selects 100 images from the dataset and plots them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data(X, example_width=None, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Displays 2D data stored in X in a nice grid.\n",
    "    100 digits in 10*10 shape\n",
    "    \"\"\"\n",
    "    # Compute rows, cols\n",
    "    if X.ndim == 2:\n",
    "        m, n = X.shape\n",
    "    elif X.ndim == 1:\n",
    "        n = X.size\n",
    "        m = 1\n",
    "        X = X[None]  # Promote to a 2 dimensional array\n",
    "    else:\n",
    "        raise IndexError('Input X should be 1 or 2 dimensional.')\n",
    "\n",
    "    example_width = example_width or int(np.round(np.sqrt(n)))\n",
    "    example_height = n / example_width\n",
    "\n",
    "    # Compute number of items to display\n",
    "    display_rows = int(np.floor(np.sqrt(m)))\n",
    "    display_cols = int(np.ceil(m / display_rows))\n",
    "\n",
    "    fig, ax_array = plt.subplots(display_rows, display_cols, figsize=figsize)\n",
    "    fig.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "\n",
    "    ax_array = [ax_array] if m == 1 else ax_array.ravel()\n",
    "\n",
    "    for i, ax in enumerate(ax_array):\n",
    "        ax.imshow(X[i].reshape(example_width, example_width, order='F'),\n",
    "                  cmap='Greys', extent=[0, 1, 0, 1])\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly select 100 data points to display\n",
    "rand_indices = np.random.choice(m, 100, replace=False)\n",
    "sel = X[rand_indices, :]\n",
    "# call display_data to show data\n",
    "display_data(sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Model representation\n",
    "\n",
    "Our neural network is shown in the following figure.\n",
    "\n",
    "![](Figures/neural_network.png)\n",
    "\n",
    "It has 3 layers - an input layer, a hidden layer and an output layer. Recall that our inputs are pixel values\n",
    "of digit images. Since the images are of size $20 \\times 20$, this gives us 400 input layer units (not counting the extra bias unit which always outputs +1). The training data was loaded into the variables `X` and `y` above.\n",
    "\n",
    "You have been provided with a set of network parameters ($\\Theta^{(1)}, \\Theta^{(2)}$) already trained by us. These are stored in `ex4weights.mat` and will be loaded in the next cell of this notebook into `Theta1` and `Theta2`. The parameters have dimensions that are sized for a neural network with 25 units in the second layer and 10 output units (corresponding to the 10 digit classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the parameters you will use for this exercise\n",
    "input_layer_size  = 400  # 20x20 Input Images of Digits\n",
    "hidden_layer_size = 25   # 25 hidden units\n",
    "num_labels = 10          # 10 labels, from 0 to 9\n",
    "\n",
    "weights= loadmat(\"ex4weights.mat\")\n",
    "# Theta1 has size 25 x 401\n",
    "# Theta2 has size 10 x 26\n",
    "Theta1= weights[\"Theta1\"]\n",
    "Theta2= weights[\"Theta2\"]\n",
    "# swap first and last columns of Theta2, due to legacy from MATLAB indexing, \n",
    "# since the weight file ex3weights.mat was saved based on MATLAB indexing\n",
    "Theta2 = np.roll(Theta2, 1, axis=0)\n",
    "# Unroll parameters \n",
    "nn_params = np.concatenate([Theta1.ravel(), Theta2.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta1 Shape is: (25, 401)\n",
      "Theta2 Shape is: (10, 26)\n",
      "After concatination of two Theta, neural network parameters are: (10285,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Theta1 Shape is: {}\".format(Theta1.shape))\n",
    "print(\"Theta2 Shape is: {}\".format(Theta2.shape))\n",
    "print(\"After concatination of two Theta, neural network parameters are: {}\".format(nn_params.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Feedforward and cost function\n",
    "\n",
    "Now you will implement the cost function and gradient for the neural network. First, complete the code for the function `nn_cost_function` in the next cell to return the cost.\n",
    "\n",
    "Recall that the cost function for the neural network (without regularization) is:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m}\\sum_{k=1}^{K} \\left[ - y_k^{(i)} \\log \\left( \\left( h_\\theta \\left( x^{(i)} \\right) \\right)_k \\right) - \\left( 1 - y_k^{(i)} \\right) \\log \\left( 1 - \\left( h_\\theta \\left( x^{(i)} \\right) \\right)_k \\right) \\right]$$\n",
    "\n",
    "where $h_\\theta \\left( x^{(i)} \\right)$ is computed as shown in the neural network figure above, and K = 10 is the total number of possible labels. Note that $h_\\theta(x^{(i)})_k = a_k^{(3)}$ is the activation (output\n",
    "value) of the $k^{th}$ output unit. Also, recall that whereas the original labels (in the variable y) were 0, 1, ..., 9, for the purpose of training a neural network, we need to encode the labels as vectors containing only values 0 or 1, so that\n",
    "\n",
    "$$ y = \n",
    "\\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\\\vdots \\\\ 0 \\end{bmatrix}, \\quad\n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix}, \\quad \\cdots  \\quad \\text{or} \\qquad\n",
    "\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 1 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "For example, if $x^{(i)}$ is an image of the digit 5, then the corresponding $y^{(i)}$ (that you should use with the cost function) should be a 10-dimensional vector with $y_5 = 1$, and the other elements equal to 0.\n",
    "\n",
    "You should implement the feedforward computation that computes $h_\\theta(x^{(i)})$ for every example $i$ and sum the cost over all examples. **Your code should also work for a dataset of any size, with any number of labels** (you can assume that there are always at least $K \\ge 3$ labels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid function given the input z.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array_like\n",
    "        The input to the sigmoid function. This can be a 1-D vector \n",
    "        or a 2-D matrix. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    g : array_like\n",
    "        The computed sigmoid function. g has the same shape as z, since\n",
    "        the sigmoid is computed element-wise on z.\n",
    "    \"\"\"\n",
    "    # convert every element to numpy array (matrix, vector or scalar)\n",
    "    z = np.array(z)\n",
    "    # create free space as size as input \n",
    "    g = np.zeros(z.shape)\n",
    "    # computing sigmoid function\n",
    "    g = (1 / (1 + np.exp(-z)))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_=0.0):\n",
    "    \"\"\"\n",
    "    Implements the neural network cost function and gradient for a two layer neural \n",
    "    network which performs classification. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nn_params : array_like\n",
    "        The parameters for the neural network which are \"unrolled\" into \n",
    "        a vector. This needs to be converted back into the weight matrices Theta1\n",
    "        and Theta2.\n",
    "    \n",
    "    input_layer_size : int\n",
    "        Number of features for the input layer. \n",
    "    \n",
    "    hidden_layer_size : int\n",
    "        Number of hidden units in the second layer.\n",
    "    \n",
    "    num_labels : int\n",
    "        Total number of labels, or equivalently number of units in output layer. \n",
    "    \n",
    "    X : array_like\n",
    "        Input dataset. A matrix of shape (m x input_layer_size).\n",
    "    \n",
    "    y : array_like\n",
    "        Dataset labels. A vector of shape (m,).\n",
    "    \n",
    "    lambda_ : float, optional\n",
    "        Regularization parameter.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The computed value for the cost function at the current weight values.\n",
    "    \n",
    "    grad : array_like\n",
    "        An \"unrolled\" vector of the partial derivatives of the concatenatation of\n",
    "        neural network weights Theta1 and Theta2.\n",
    "    \"\"\"\n",
    "    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n",
    "    # for our 2 layer neural network\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], (hidden_layer_size, (input_layer_size + 1)))\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):], (num_labels, (hidden_layer_size + 1)))\n",
    "\n",
    "    # Setup some useful variables\n",
    "    m = y.size\n",
    "         \n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    \n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    \n",
    "    a2 = sigmoid(a1.dot(Theta1.T))\n",
    "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
    "    \n",
    "    a3 = sigmoid(a2.dot(Theta2.T))\n",
    "    \n",
    "    # y is our outputs, we create output vector \n",
    "    y_matrix = y.reshape(-1)\n",
    "    y_matrix = np.eye(num_labels)[y_matrix]\n",
    "    \n",
    "    J = (-1 / m) * np.sum((np.log(a3) * y_matrix) + np.log(1 - a3) * (1 - y_matrix))\n",
    "    \n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done, call your `nn_cost_function` using the loaded set of parameters for `Theta1` and `Theta2`. You should see that the cost is about 0.287629."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at parameters (loaded from ex4weights): 0.287629 \n",
      "The cost should be about                   : 0.287629.\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0\n",
    "J, _ = nn_cost_function(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_)\n",
    "print(\"Cost at parameters (loaded from ex4weights): {:.6f} \".format(J))\n",
    "print(\"The cost should be about                   : 0.287629.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Regularized cost function\n",
    "\n",
    "The cost function for neural networks with regularization is given by:\n",
    "\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m}\\sum_{k=1}^{K} \\left[ - y_k^{(i)} \\log \\left( \\left( h_\\theta \\left( x^{(i)} \\right) \\right)_k \\right) - \\left( 1 - y_k^{(i)} \\right) \\log \\left( 1 - \\left( h_\\theta \\left( x^{(i)} \\right) \\right)_k \\right) \\right] + \\frac{\\lambda}{2 m} \\left[ \\sum_{j=1}^{25} \\sum_{k=1}^{400} \\left( \\Theta_{j,k}^{(1)} \\right)^2 + \\sum_{j=1}^{10} \\sum_{k=1}^{25} \\left( \\Theta_{j,k}^{(2)} \\right)^2 \\right] $$\n",
    "\n",
    "You can assume that the neural network will only have 3 layers - an input layer, a hidden layer and an output layer. However, your code should work for any number of input units, hidden units and outputs units. While we\n",
    "have explicitly listed the indices above for $\\Theta^{(1)}$ and $\\Theta^{(2)}$ for clarity, do note that your code should in general work with $\\Theta^{(1)}$ and $\\Theta^{(2)}$ of any size. Note that you should not be regularizing the terms that correspond to the bias. For the matrices `Theta1` and `Theta2`, this corresponds to the first column of each matrix. You should now add regularization to your cost function. Notice that you can first compute the unregularized cost function $J$ using your existing `nn_cost_function` and then later add the cost for the regularization terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function_regularized(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_=0.0):\n",
    "    \"\"\"\n",
    "    Implements the neural network cost function and gradient for a two layer neural \n",
    "    network which performs classification. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nn_params : array_like\n",
    "        The parameters for the neural network which are \"unrolled\" into \n",
    "        a vector. This needs to be converted back into the weight matrices Theta1\n",
    "        and Theta2.\n",
    "    \n",
    "    input_layer_size : int\n",
    "        Number of features for the input layer. \n",
    "    \n",
    "    hidden_layer_size : int\n",
    "        Number of hidden units in the second layer.\n",
    "    \n",
    "    num_labels : int\n",
    "        Total number of labels, or equivalently number of units in output layer. \n",
    "    \n",
    "    X : array_like\n",
    "        Input dataset. A matrix of shape (m x input_layer_size).\n",
    "    \n",
    "    y : array_like\n",
    "        Dataset labels. A vector of shape (m,).\n",
    "    \n",
    "    lambda_ : float, optional\n",
    "        Regularization parameter.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The computed value for the cost function at the current weight values.\n",
    "    \n",
    "    grad : array_like\n",
    "        An \"unrolled\" vector of the partial derivatives of the concatenatation of\n",
    "        neural network weights Theta1 and Theta2.\n",
    "    \"\"\"\n",
    "    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n",
    "    # for our 2 layer neural network\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)], (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):], (num_labels, (hidden_layer_size + 1)))\n",
    "\n",
    "    # Setup some useful variables\n",
    "    m = y.size\n",
    "         \n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    \n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    \n",
    "    a2 = sigmoid(a1.dot(Theta1.T))\n",
    "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
    "    \n",
    "    a3 = sigmoid(a2.dot(Theta2.T))\n",
    "    \n",
    "    y_matrix = y.reshape(-1)\n",
    "    y_matrix = np.eye(num_labels)[y_matrix]\n",
    "    \n",
    "    temp1 = Theta1\n",
    "    temp2 = Theta2\n",
    "    \n",
    "    # Add regularization term\n",
    "    \n",
    "    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])))\n",
    "    \n",
    "    J = (-1 / m) * np.sum((np.log(a3) * y_matrix) + np.log(1 - a3) * (1 - y_matrix)) + reg_term\n",
    "    \n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done, the next cell will call your `nn_cost_function_regularized` using the loaded set of parameters for `Theta1` and `Theta2`, and $\\lambda = 1$. You should see that the cost is about 0.383770."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at parameters (loaded from ex4weights): 0.383770\n",
      "This value should be about                 : 0.383770.\n"
     ]
    }
   ],
   "source": [
    "# Weight regularization parameter (we set this to 1 here).\n",
    "lambda_ = 1\n",
    "J, _ = nn_cost_function_regularized(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_)\n",
    "\n",
    "print('Cost at parameters (loaded from ex4weights): %.6f' % J)\n",
    "print('This value should be about                 : 0.383770.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Backpropagation\n",
    "\n",
    "In this part of the exercise, you will implement the backpropagation algorithm to compute the gradient for the neural network cost function. You will need to update the function `nnCostFunction` so that it returns an appropriate value for `grad`. Once you have computed the gradient, you will be able to train the neural network by minimizing the cost function $J(\\theta)$ using an advanced optimizer such as `scipy`'s `optimize.minimize`.\n",
    "You will first implement the backpropagation algorithm to compute the gradients for the parameters for the (unregularized) neural network. After you have verified that your gradient computation for the unregularized case is correct, you will implement the gradient for the regularized neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Sigmoid Gradient\n",
    "\n",
    "To help you get started with this part of the exercise, you will first implement\n",
    "the sigmoid gradient function. The gradient for the sigmoid function can be\n",
    "computed as\n",
    "\n",
    "$$ g'(z) = \\frac{d}{dz} g(z) = g(z)\\left(1-g(z)\\right) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\text{sigmoid}(z) = g(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "Now complete the implementation of `sigmoid_gradient` in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the sigmoid function evaluated at z. \n",
    "    This should work regardless if z is a matrix or a vector. \n",
    "    In particular, if z is a vector or matrix, you should return\n",
    "    the gradient for each element.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array_like\n",
    "        A vector or matrix as input to the sigmoid function. \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    g : array_like\n",
    "        Gradient of the sigmoid function. Has the same shape as z. \n",
    "    \"\"\"\n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    g = sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done, the following cell call `sigmoid_gradient` on a given vector `z`. Try testing a few values by calling `sigmoid_gradient(z)`. For large values (both positive and negative) of z, the gradient should be close to 0. When $z = 0$, the gradient should be exactly 0.25. Your code should also work with vectors and matrices. For a matrix, your function should perform the sigmoid gradient function on every element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid gradient evaluated at [-1 -0.5 0 0.5 1]:\n",
      "  \n",
      "[0.19661193 0.23500371 0.25       0.23500371 0.19661193]\n"
     ]
    }
   ],
   "source": [
    "z = np.array([-1, -0.5, 0, 0.5, 1])\n",
    "g = sigmoid_gradient(z)\n",
    "print('Sigmoid gradient evaluated at [-1 -0.5 0 0.5 1]:\\n  ')\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Random Initialization\n",
    "\n",
    "When training neural networks, it is important to randomly initialize the parameters for symmetry breaking. One effective strategy for random initialization is to randomly select values for $\\Theta^{(l)}$ uniformly in the range $[-\\epsilon_{init}, \\epsilon_{init}]$. You should use $\\epsilon_{init} = 0.12$. This range of values ensures that the parameters are kept small and makes the learning more efficient.\n",
    "\n",
    "<div class=\"alert alert-box alert-warning\">\n",
    "One effective strategy for choosing $\\epsilon_{init}$ is to base it on the number of units in the network. A good choice of $\\epsilon_{init}$ is $\\epsilon_{init} = \\frac{\\sqrt{6}}{\\sqrt{L_{in} + L_{out}}}$ where $L_{in} = s_l$ and $L_{out} = s_{l+1}$ are the number of units in the layers adjacent to $\\Theta^{l}$.\n",
    "</div>\n",
    "\n",
    "Your job is to complete the function `rand_initialize_weights` to initialize the weights for $\\Theta$. Modify the function by filling in the following code:\n",
    "\n",
    "```python\n",
    "# Randomly initialize the weights to small values\n",
    "W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "```\n",
    "Note that we give the function an argument for $\\epsilon$ with default value `epsilon_init = 0.12`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_initialize_weights(L_in, L_out, epsilon_init=0.12):\n",
    "    \"\"\"\n",
    "    Randomly initialize the weights of a layer in a neural network.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    L_in : int\n",
    "        Number of incomming connections.\n",
    "    \n",
    "    L_out : int\n",
    "        Number of outgoing connections. \n",
    "    \n",
    "    epsilon_init : float, optional\n",
    "        Range of values which the weight can take from a uniform \n",
    "        distribution.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    W : array_like\n",
    "        The weight initialiatized to random values.  Note that W should\n",
    "        be set to a matrix of size(L_out, 1 + L_in) as\n",
    "        the first column of W handles the \"bias\" terms.\n",
    "    \"\"\"\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "\n",
    "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to initialize the weights for the 2 layers in the neural network using the `rand_initialize_weights` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Neural Network Parameters ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Neural Network Parameters ...\")\n",
    "\n",
    "initial_Theta1 = rand_initialize_weights(input_layer_size, hidden_layer_size)\n",
    "initial_Theta2 = rand_initialize_weights(hidden_layer_size, num_labels)\n",
    "\n",
    "# Unroll parameters\n",
    "initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Backpropagation\n",
    "\n",
    "![](Figures/ex4-backpropagation.png)\n",
    "\n",
    "Now, you will implement the backpropagation algorithm. Recall that the intuition behind the backpropagation algorithm is as follows. Given a training example $(x^{(t)}, y^{(t)})$, we will first run a “forward pass” to compute all the activations throughout the network, including the output value of the hypothesis $h_\\theta(x)$. Then, for each node $j$ in layer $l$, we would like to compute an “error term” $\\delta_j^{(l)}$ that measures how much that node was “responsible” for any errors in our output.\n",
    "\n",
    "For an output node, we can directly measure the difference between the network’s activation and the true target value, and use that to define $\\delta_j^{(3)}$ (since layer 3 is the output layer). For the hidden units, you will compute $\\delta_j^{(l)}$ based on a weighted average of the error terms of the nodes in layer $(l+1)$. In detail, here is the backpropagation algorithm (also depicted in the figure above). You should implement steps 1 to 4 in a loop that processes one example at a time. Concretely, you should implement a for-loop `for t in range(m)` and place steps 1-4 below inside the for-loop, with the $t^{th}$ iteration performing the calculation on the $t^{th}$ training example $(x^{(t)}, y^{(t)})$. Step 5 will divide the accumulated gradients by $m$ to obtain the gradients for the neural network cost function.\n",
    "\n",
    "1. Set the input layer’s values $(a^{(1)})$ to the $t^{th }$training example $x^{(t)}$. Perform a feedforward pass, computing the activations $(z^{(2)}, a^{(2)}, z^{(3)}, a^{(3)})$ for layers 2 and 3. Note that you need to add a `+1` term to ensure that the vectors of activations for layers $a^{(1)}$ and $a^{(2)}$ also include the bias unit. In `numpy`, if a 1 is a column matrix, adding one corresponds to `a_1 = np.concatenate([np.ones((m, 1)), a_1], axis=1)`.\n",
    "\n",
    "1. For each output unit $k$ in layer 3 (the output layer), set \n",
    "$$\\delta_k^{(3)} = \\left(a_k^{(3)} - y_k \\right)$$\n",
    "where $y_k \\in \\{0, 1\\}$ indicates whether the current training example belongs to class $k$ $(y_k = 1)$, or if it belongs to a different class $(y_k = 0)$. You may find logical arrays helpful for this task (explained in the previous programming exercise).\n",
    "\n",
    "1. For the hidden layer $l = 2$, set \n",
    "$$ \\delta^{(2)} = \\left( \\Theta^{(2)} \\right)^T \\delta^{(3)} * g'\\left(z^{(2)} \\right)$$\n",
    "Note that the symbol $*$ performs element wise multiplication in `numpy`.\n",
    "\n",
    "1. Accumulate the gradient from this example using the following formula. Note that you should skip or remove $\\delta_0^{(2)}$. In `numpy`, removing $\\delta_0^{(2)}$ corresponds to `delta_2 = delta_2[1:]`.\n",
    "\n",
    "1. Obtain the (unregularized) gradient for the neural network cost function by dividing the accumulated gradients by $\\frac{1}{m}$:\n",
    "$$ \\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J(\\Theta) = D_{ij}^{(l)} = \\frac{1}{m} \\Delta_{ij}^{(l)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have implemented the backpropagation algorithm, we will proceed to run gradient checking on your implementation. The gradient check will allow you to increase your confidence that your code is\n",
    "computing the gradients correctly.\n",
    "\n",
    "### 2.4  Gradient checking \n",
    "\n",
    "In your neural network, you are minimizing the cost function $J(\\Theta)$. To perform gradient checking on your parameters, you can imagine “unrolling” the parameters $\\Theta^{(1)}$, $\\Theta^{(2)}$ into a long vector $\\theta$. By doing so, you can think of the cost function being $J(\\Theta)$ instead and use the following gradient checking procedure.\n",
    "\n",
    "Suppose you have a function $f_i(\\theta)$ that purportedly computes $\\frac{\\partial}{\\partial \\theta_i} J(\\theta)$; you’d like to check if $f_i$ is outputting correct derivative values.\n",
    "\n",
    "$$\n",
    "\\text{Let } \\theta^{(i+)} = \\theta + \\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ \\epsilon \\\\ \\vdots \\\\ 0 \\end{bmatrix}\n",
    "\\quad \\text{and} \\quad \\theta^{(i-)} = \\theta - \\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ \\epsilon \\\\ \\vdots \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So, $\\theta^{(i+)}$ is the same as $\\theta$, except its $i^{th}$ element has been incremented by $\\epsilon$. Similarly, $\\theta^{(i−)}$ is the corresponding vector with the $i^{th}$ element decreased by $\\epsilon$. You can now numerically verify $f_i(\\theta)$’s correctness by checking, for each $i$, that:\n",
    "\n",
    "$$ f_i\\left( \\theta \\right) \\approx \\frac{J\\left( \\theta^{(i+)}\\right) - J\\left( \\theta^{(i-)} \\right)}{2\\epsilon} $$\n",
    "\n",
    "The degree to which these two values should approximate each other will depend on the details of $J$. But assuming $\\epsilon = 10^{-4}$, you’ll usually find that the left- and right-hand sides of the above will agree to at least 4 significant digits (and often many more).\n",
    "\n",
    "We have implemented the function to compute the numerical gradient for you in `compute_numerical_gradient`. While you are not required to modify the file, we highly encourage you to take a look at the code to understand how it works.\n",
    "\n",
    "In the next cell we will run the provided function `check_nn_gradients` which will create a small neural network and dataset that will be used for checking your gradients. If your backpropagation implementation is correct,\n",
    "you should see a relative difference that is less than 1e-9.\n",
    "\n",
    "\n",
    "**Practical Tip**: When performing gradient checking, it is much more efficient to use a small neural network with a relatively small number of input units and hidden units, thus having a relatively small number\n",
    "of parameters. Each dimension of $\\theta$ requires two evaluations of the cost function and this can be expensive. In the function `check_nn_gradients`, our code creates a small random model and dataset which is used with `compute_numerical_gradient` for gradient checking. Furthermore, after you are confident that your gradient computations are correct, you should turn off gradient checking before running your learning algorithm.\n",
    "\n",
    "**Practical Tip:** Gradient checking works for any function where you are computing the cost and the gradient. Concretely, you can use the same `compute_numerical_gradient` function to check if your gradient implementations for the other exercises are correct too (e.g., logistic regression’s cost function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function(nn_params,\n",
    "                   input_layer_size,\n",
    "                   hidden_layer_size,\n",
    "                   num_labels,\n",
    "                   X, y, lambda_=0.0):\n",
    "    \"\"\"\n",
    "    Implements the neural network cost function and gradient for a two layer neural \n",
    "    network which performs classification. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nn_params : array_like\n",
    "        The parameters for the neural network which are \"unrolled\" into \n",
    "        a vector. This needs to be converted back into the weight matrices Theta1\n",
    "        and Theta2.\n",
    "    \n",
    "    input_layer_size : int\n",
    "        Number of features for the input layer. \n",
    "    \n",
    "    hidden_layer_size : int\n",
    "        Number of hidden units in the second layer.\n",
    "    \n",
    "    num_labels : int\n",
    "        Total number of labels, or equivalently number of units in output layer. \n",
    "    \n",
    "    X : array_like\n",
    "        Input dataset. A matrix of shape (m x input_layer_size).\n",
    "    \n",
    "    y : array_like\n",
    "        Dataset labels. A vector of shape (m,).\n",
    "    \n",
    "    lambda_ : float, optional\n",
    "        Regularization parameter.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The computed value for the cost function at the current weight values.\n",
    "    \n",
    "    grad : array_like\n",
    "        An \"unrolled\" vector of the partial derivatives of the concatenatation of\n",
    "        neural network weights Theta1 and Theta2.\n",
    "    \n",
    "    Note \n",
    "    ----\n",
    "    We have provided an implementation for the sigmoid function in the file \n",
    "    `utils.py` accompanying this assignment.\n",
    "    \"\"\"\n",
    "    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n",
    "    # for our 2 layer neural network\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "\n",
    "    # Setup some useful variables\n",
    "    m = y.size\n",
    "         \n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    \n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    \n",
    "    a2 = sigmoid(a1.dot(Theta1.T))\n",
    "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
    "    \n",
    "    a3 = sigmoid(a2.dot(Theta2.T))\n",
    "    \n",
    "    y_matrix = y.reshape(-1)\n",
    "    y_matrix = np.eye(num_labels)[y_matrix]\n",
    "    \n",
    "    temp1 = Theta1\n",
    "    temp2 = Theta2\n",
    "    \n",
    "    # Add regularization term\n",
    "    \n",
    "    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])))\n",
    "    \n",
    "    J = (-1 / m) * np.sum((np.log(a3) * y_matrix) + np.log(1 - a3) * (1 - y_matrix)) + reg_term\n",
    "    \n",
    "    # Backpropogation\n",
    "    \n",
    "    delta_3 = a3 - y_matrix\n",
    "    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoid_gradient(a1.dot(Theta1.T))\n",
    "\n",
    "    Delta1 = delta_2.T.dot(a1)\n",
    "    Delta2 = delta_3.T.dot(a2)\n",
    "    \n",
    "    # Add regularization to gradient\n",
    "\n",
    "    Theta1_grad = (1 / m) * Delta1\n",
    "    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n",
    "    \n",
    "    Theta2_grad = (1 / m) * Delta2\n",
    "    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n",
    "       \n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_initialize_weights(fan_out, fan_in):\n",
    "    \"\"\"\n",
    "    Initialize the weights of a layer with fan_in incoming connections and fan_out outgoings\n",
    "    connections using a fixed strategy. This will help you later in debugging.\n",
    "\n",
    "    Note that W should be set a matrix of size (1+fan_in, fan_out) as the first row of W handles\n",
    "    the \"bias\" terms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fan_out : int\n",
    "        The number of outgoing connections.\n",
    "\n",
    "    fan_in : int\n",
    "        The number of incoming connections.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    W : array_like (1+fan_in, fan_out)\n",
    "        The initialized weights array given the dimensions.\n",
    "    \"\"\"\n",
    "    # Initialize W using \"sin\". This ensures that W is always of the same values and will be\n",
    "    # useful for debugging\n",
    "    W = np.sin(np.arange(1, 1 + (1+fan_in)*fan_out))/10.0\n",
    "    W = W.reshape(fan_out, 1+fan_in, order='F')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_numerical_gradient(J, theta, e=1e-4):\n",
    "    \"\"\"\n",
    "    Computes the gradient using \"finite differences\" and gives us a numerical estimate of the\n",
    "    gradient.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    J : func\n",
    "        The cost function which will be used to estimate its numerical gradient.\n",
    "\n",
    "    theta : array_like\n",
    "        The one dimensional unrolled network parameters. The numerical gradient is computed at\n",
    "         those given parameters.\n",
    "\n",
    "    e : float (optional)\n",
    "        The value to use for epsilon for computing the finite difference.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The following code implements numerical gradient checking, and\n",
    "    returns the numerical gradient. It sets `numgrad[i]` to (a numerical\n",
    "    approximation of) the partial derivative of J with respect to the\n",
    "    i-th input argument, evaluated at theta. (i.e., `numgrad[i]` should\n",
    "    be the (approximately) the partial derivative of J with respect\n",
    "    to theta[i].)\n",
    "    \"\"\"\n",
    "    numgrad = np.zeros(theta.shape)\n",
    "    perturb = np.diag(e * np.ones(theta.shape))\n",
    "    for i in range(theta.size):\n",
    "        loss1, _ = J(theta - perturb[:, i])\n",
    "        loss2, _ = J(theta + perturb[:, i])\n",
    "        numgrad[i] = (loss2 - loss1)/(2*e)\n",
    "    return numgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nn_gradients(nn_cost_function, lambda_=0):\n",
    "    \"\"\"\n",
    "    Creates a small neural network to check the backpropagation gradients. It will output the\n",
    "    analytical gradients produced by your backprop code and the numerical gradients\n",
    "    (computed using compute_numerical_gradient). These two gradient computations should result in\n",
    "    very similar values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nnCostFunction : func\n",
    "        A reference to the cost function implemented by the student.\n",
    "\n",
    "    lambda_ : float (optional)\n",
    "        The regularization parameter value.\n",
    "    \"\"\"\n",
    "    input_layer_size = 3\n",
    "    hidden_layer_size = 5\n",
    "    num_labels = 3\n",
    "    m = 5\n",
    "\n",
    "    # We generate some 'random' test data\n",
    "    Theta1 = debug_initialize_weights(hidden_layer_size, input_layer_size)\n",
    "    Theta2 = debug_initialize_weights(num_labels, hidden_layer_size)\n",
    "\n",
    "    # Reusing debugInitializeWeights to generate X\n",
    "    X = debug_initialize_weights(m, input_layer_size - 1)\n",
    "    y = np.arange(1, 1+m) % num_labels\n",
    "    # print(y)\n",
    "    # Unroll parameters\n",
    "    nn_params = np.concatenate([Theta1.ravel(), Theta2.ravel()])\n",
    "\n",
    "    # short hand for cost function\n",
    "    cost_func = lambda p: nn_cost_function(p, input_layer_size, hidden_layer_size,\n",
    "                                        num_labels, X, y, lambda_)\n",
    "    cost, grad = cost_func(nn_params)\n",
    "    numgrad = compute_numerical_gradient(cost_func, nn_params)\n",
    "\n",
    "    # Visually examine the two gradient computations.The two columns you get should be very similar.\n",
    "    print(np.stack([numgrad, grad], axis=1))\n",
    "    print('The above two columns you get should be very similar.')\n",
    "    print('(Left-Your Numerical Gradient, Right-Analytical Gradient)\\n')\n",
    "\n",
    "    # Evaluate the norm of the difference between two the solutions. If you have a correct\n",
    "    # implementation, and assuming you used e = 0.0001 in computeNumericalGradient, then diff\n",
    "    # should be less than 1e-9.\n",
    "    diff = np.linalg.norm(numgrad - grad)/np.linalg.norm(numgrad + grad)\n",
    "\n",
    "    print('If your backpropagation implementation is correct, then \\n'\n",
    "          'the relative difference will be small (less than 1e-9). \\n'\n",
    "          'Relative Difference: %g' % diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.27825235e-03 -9.27825236e-03]\n",
      " [-3.04978709e-06 -3.04978914e-06]\n",
      " [-1.75060084e-04 -1.75060082e-04]\n",
      " [-9.62660640e-05 -9.62660620e-05]\n",
      " [ 8.89911959e-03  8.89911960e-03]\n",
      " [ 1.42869450e-05  1.42869443e-05]\n",
      " [ 2.33146358e-04  2.33146357e-04]\n",
      " [ 1.17982666e-04  1.17982666e-04]\n",
      " [-8.36010761e-03 -8.36010762e-03]\n",
      " [-2.59383093e-05 -2.59383100e-05]\n",
      " [-2.87468729e-04 -2.87468729e-04]\n",
      " [-1.37149709e-04 -1.37149706e-04]\n",
      " [ 7.62813550e-03  7.62813551e-03]\n",
      " [ 3.69883257e-05  3.69883234e-05]\n",
      " [ 3.35320351e-04  3.35320347e-04]\n",
      " [ 1.53247082e-04  1.53247082e-04]\n",
      " [-6.74798369e-03 -6.74798370e-03]\n",
      " [-4.68759764e-05 -4.68759769e-05]\n",
      " [-3.76215583e-04 -3.76215587e-04]\n",
      " [-1.66560294e-04 -1.66560294e-04]\n",
      " [ 3.14544970e-01  3.14544970e-01]\n",
      " [ 1.64090819e-01  1.64090819e-01]\n",
      " [ 1.64567932e-01  1.64567932e-01]\n",
      " [ 1.58339334e-01  1.58339334e-01]\n",
      " [ 1.51127527e-01  1.51127527e-01]\n",
      " [ 1.49568335e-01  1.49568335e-01]\n",
      " [ 1.11056588e-01  1.11056588e-01]\n",
      " [ 5.75736494e-02  5.75736493e-02]\n",
      " [ 5.77867378e-02  5.77867378e-02]\n",
      " [ 5.59235296e-02  5.59235296e-02]\n",
      " [ 5.36967009e-02  5.36967009e-02]\n",
      " [ 5.31542052e-02  5.31542052e-02]\n",
      " [ 9.74006970e-02  9.74006970e-02]\n",
      " [ 5.04575855e-02  5.04575855e-02]\n",
      " [ 5.07530173e-02  5.07530173e-02]\n",
      " [ 4.91620841e-02  4.91620841e-02]\n",
      " [ 4.71456249e-02  4.71456249e-02]\n",
      " [ 4.65597186e-02  4.65597186e-02]]\n",
      "The above two columns you get should be very similar.\n",
      "(Left-Your Numerical Gradient, Right-Analytical Gradient)\n",
      "\n",
      "If your backpropagation implementation is correct, then \n",
      "the relative difference will be small (less than 1e-9). \n",
      "Relative Difference: 2.41486e-11\n"
     ]
    }
   ],
   "source": [
    "check_nn_gradients(nn_cost_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Regularized Neural Network\n",
    "\n",
    "After you have successfully implemented the backpropagation algorithm, you will add regularization to the gradient. To account for regularization, it turns out that you can add this as an additional term *after* computing the gradients using backpropagation.\n",
    "\n",
    "Specifically, after you have computed $\\Delta_{ij}^{(l)}$ using backpropagation, you should add regularization using\n",
    "\n",
    "$$ \\begin{align} \n",
    "& \\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J(\\Theta) = D_{ij}^{(l)} = \\frac{1}{m} \\Delta_{ij}^{(l)} & \\qquad \\text{for } j = 0 \\\\\n",
    "& \\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J(\\Theta) = D_{ij}^{(l)} = \\frac{1}{m} \\Delta_{ij}^{(l)} + \\frac{\\lambda}{m} \\Theta_{ij}^{(l)} & \\qquad \\text{for } j \\ge 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that you should *not* be regularizing the first column of $\\Theta^{(l)}$ which is used for the bias term. Furthermore, in the parameters $\\Theta_{ij}^{(l)}$, $i$ is indexed starting from 1, and $j$ is indexed starting from 0. Thus, \n",
    "\n",
    "$$\n",
    "\\Theta^{(l)} = \\begin{bmatrix}\n",
    "\\Theta_{1,0}^{(i)} & \\Theta_{1,1}^{(l)} & \\cdots \\\\\n",
    "\\Theta_{2,0}^{(i)} & \\Theta_{2,1}^{(l)} & \\cdots \\\\\n",
    "\\vdots &  ~ & \\ddots\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "After you are done, the following cell runs gradient checking on your implementation. If your code is correct, you should expect to see a relative difference that is less than 1e-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
